## Seungone Kim (김승원)

#### Info about me...
Hello! I am a first year M.S. Student at the Language & Knowledge Lab at KAIST, advised by Minjoon Seo.<br>
My main research goal is to make techniques that ensure neural models are aligned with human values in order to reduce the substantial risks they might have (also known the the "Alignment Problem").<br>
<br>
Specifically, I am interested in, <br>
(1) enabling LMs to truly follow human instructions <br>
(2) teaching LMs to express their thought process <br>
(3) ensuring LMs to share commonsense knowledge as humans do <br>
(4) enforcing LMs to generate helpful & factual responses <br>
<br>
In addition, I also enjoy thinking of neural architectures that might have better inductive biases than Transformers.<br>
<br>
Reach out to me via email (louisdebroglie@kaist.ac.kr) if you have any questions, or would like to cooperate with me!
