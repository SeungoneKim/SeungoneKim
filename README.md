## Seungone Kim (김승원)

#### Info about me...
Hello! I am a first year M.S. Student at the Language & Knowledge Lab at KAIST, advised by Minjoon Seo.<br>
I am also a research intern at the Language Team at Naver AI Lab, advised by Jamin Shin.<br>
My main research goal is to make techniques that ensure neural models are aligned with human values in order to reduce the substantial risks they might have (also known the the "Alignment Problem").<br>
<br>
Specifically, I am interested in, <br>
(1) ensuring LMs to truly follow human instructions (e.g., Instruction Tuning, RLHF, Fine-grained Evaluation): ELM (ICML 2023), Flask Evaluation (preprint)<br>
(2) teaching LMs to express their thought process: CoTEVer (EACL 2023), CoT Collection (preprint)<br>
(3) grounding LMs to share commonsense knowledge as humans do: SICK (COLING 2022) <br>
<br>
I am actively looking for a PhD position at the US (admission for Fall 2024)!<br>
<br>
Reach out to me via email (louisdebroglie@kaist.ac.kr) if you have any questions, or would like to collaborate with me!<br>
